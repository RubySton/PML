df <- select(testing, one_of(vars))
class(df)
dim(df)
pred <- predict(model, df)
pred <- predict(model, testing[,df])
pred <- predict(model, testing[df,])
pred <- predict(model, testing[df])
pred <- predict(model, testing$df)
pred[c( TotalIntench2 = 57,000, FiberWidthCh1 = 8,VarIntenCh4 = 100)]
pred[ TotalIntench2 = 57,000 & FiberWidthCh1 = 8 & VarIntenCh4 = 100)]
pred[ TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
pred[ TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100]
pred[which( TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
pred[which(df[, TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
pred[which(df[, TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100])]
pred[c( FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)]
arrang(testing, "Class","FiberWidthCh1","PerimStatusCh1","TotalIntenCh2","VarIntenCh4")
library(dplyr)
data <- arrang(testing, "Class","FiberWidthCh1","PerimStatusCh1","TotalIntenCh2","VarIntenCh4", desc(varIntenCh4))
data <- arrange(testing, "Class","FiberWidthCh1","PerimStatusCh1","TotalIntenCh2","VarIntenCh4", desc(varIntenCh4))
testing <- nrow(testing)-1
dim(testing)
length(testing)
testing
names(testing)
?split.data.frame
head(df)
head(df,20)
tail(df,20)
predclass=predict(model$class)
pred[which(df[, TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100])]
predict(model,df)
predict(model,testing)
predict(model,testing$df)
pred <- predict(model, testing$df)
pred <- predict(model$finalModel, testing$df)
pred[, TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100])]
pred[, TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100]
pred[TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100]
pred[cbind(TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
pred[c(TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
pred(TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)
newdata <-testing[,-c(FiberWidthCh1,PerimStatusCh1,TotalIntenCh2,VarIntenCh4)]
?which
pred[which(TotalIntench2 == 57,000 & FiberWidthCh1 == 8 & VarIntenCh4 == 100)]
library(AppliedPredictiveModeling);
data(segmentationOriginal);
library(caret)
training <- subset(segmentationOriginal, Case == "Train",select = - Case)
testning <- subset(segmentationOriginal, Case == "Test",select = - Case)
set.seed(125)
trainIndices = createDataPartition(training$Class, p = 0.8, list = F)
wanted = !colnames(training) %in% c("FiberWidthCh1","PerimStatusCh1","TotalIntenCh2","VarIntenCh4"))
new_train = training[trainIndices, wanted]
new_test = training[-trainIndices, wanted]
wanted <- !colnames(training) %in% c("FiberWidthCh1","PerimStatusCh1","TotalIntenCh2","VarIntenCh4")
new_train = training[trainIndices, wanted]
new_test = training[-trainIndices, wanted]
cv_opts = trainControl(method="cv", number=10)
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(125)
model <- train(Class ~., method= "rpart", data = new_train,
control = rpart.control(cp = 0.05))
preds = predict(model, new_test[,-2])
preds[c(  "FiberWidthCh1" = 8,"PerimStatusCh1"== ,"TotalIntench2" ==57,000,"VarIntenCh4" = 100)]
preds[c("FiberWidthCh1" = 8,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[data.frame("FiberWidthCh1" = 8,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[as.data.frame("FiberWidthCh1" = 8,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind.data.frame("FiberWidthCh1" = 8,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind("FiberWidthCh1" = 8,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind("FiberWidthCh1" = 8,"PerimStatusCh1"== ,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind("FiberWidthCh1" = 8,"PerimStatusCh1" ,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind("FiberWidthCh1" = 8,"PerimStatusCh1"==0 ,"TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind(TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[cbind("TotalIntench2" ==57000,"VarIntenCh4" = 100)]
preds[c(TotalIntench2 = 23,000, FiberWidthCh1 = 10)]
preds[cbind(TotalIntench2 = 23,000, FiberWidthCh1 = 10)]
preds[cbind("TotalIntench2" == 23000, "FiberWidthCh1"== 10)]
preds[cbind("TotalIntench2" == 23000, "FiberWidthCh1"= 10)]
preds[cbind("TotalIntench2" == 50000, "VarIntenCh4" = 100)]
preds[cbind( FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)]
preds[cbind( "FiberWidthCh1"== 8, "VarIntenCh4" == 100, "PerimStatusCh1"=2)]
Preds[cbind( "FiberWidthCh1" = 10, "PerimStatusCh1"==2 ,"TotalIntench2" == 23,000)]
preds[cbind( "FiberWidthCh1" = 10, "PerimStatusCh1"==2 ,"TotalIntench2" == 23,000)]
preds[cbind("FiberWidthCh1"== 10,"TotalIntench2"== 50,000,"VarIntenCh4" == 100)]
preds[cbind("FiberWidthCh1"== 10,"TotalIntench2"== 50000,"VarIntenCh4" = 100)]
preds[cbind( "TotalIntench2" == 57000, "FiberWidthCh1" == 8,"VarIntenCh4" = 100)]
preds[cbind("FiberWidthCh1" == 8,"TotalIntench2" == 57000,"VarIntenCh4" == 100)]
preds[cbind("FiberWidthCh1" == 8,"TotalIntench2" == 57000,"VarIntenCh4" = 100)]
preds[cbind(TotalIntench2" == 57000,"VarIntenCh4" == 100)]
preds[cbind("TotalIntench2" == 57000,"VarIntenCh4" == 100)]
preds[cbind("TotalIntench2" == 57000,"VarIntenCh4" = 100)]
preds[c( FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)]
preds[c( FiberWidthCh1 == 8, VarIntenCh4 == 100, PerimStatusCh1==2)]
preds[c( "FiberWidthCh1" == 8, "VarIntenCh4" == 100, "PerimStatusCh1"==2)]
preds[c( "FiberWidthCh1" == 8, "VarIntenCh4" == 100, "PerimStatusCh1"=2)]
preds[wanted = c(8,,100,2)]
preds[wanted = c(8,"",100,2)]
preds[wanted = c(8,1,100,2)]
preds[wanted = data.frame(8,1,100,2)]
preds[wanted = cbind(8,1,100,2)]
preds[wanted = cbind(8,0,100,2)]
preds[cbind( TotalIntench2 = 57,000, FiberWidthCh1 = 8,VarIntenCh4 = 100)]
preds[c(TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)]
preds[c(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2 )]
preds[cbind(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2 )]
preds[cbind(TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)]
preds[c(TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)]
preds[c( TotalIntench2 = 57,000, FiberWidthCh1 = 8,VarIntenCh4 = 100)]
preds[c( FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)]
preds[c( FiberWidthCh1 = 8, VarIntenCh4 = 100)]
preds[c( FiberWidthCh1 == 8, VarIntenCh4 == 100)]
preds[c( FiberWidthCh1 == 8, VarIntenCh4 = 100)]
preds[cbind( FiberWidthCh1 = 8, VarIntenCh4 = 100)]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
glm.fit <- glm(chd ~ age +alcohol +obesity + tobacco +typea +ldl,family=binomial("logit"), data= trainSA)
glm.pred=predict(glm.fit,type="response", testSA)
error.glm <- testSA$chd -(glm.pred >= .5)
mean(abs(error.glm))
1- mean(abs(error.glm)
)
value <-  glm.pred >= .5
missClass(testSA$chd,value)
missClass = function(values,prediction)
{sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd,value)
missClass(trainSA$chd,value)
missClass(trainSA$chd,glm.pred)
missClass(testA$chd,glm.pred)
missClass(testSA$chd,glm.pred)
train.err <- trainSA$chd – round(predict(glm.fit,trainSA,type="response"))
Er <- round(predict(glm.fit,trainSA,type="response"))
trainSA$chd – Er
trainSA$chd - Er
train.err <-trainSA$chd - Er
round(sum(train.err^2/dim(trainSA)[1]),2)
test.err <- testSA$chd - round(predict(glm.fit,testSA,type="response"))
round(sum(test.err^2/dim(testSA)[1]),2)
library(pgmm)
help("pgmm")
install.packages("rpart.plot")
help(rpart.plot)
library(rpart.plot)
help(rpart.plot)
library(AppliedPredictiveModeling);
data(segmentationOriginal);
library(caret)
training <- subset(segmentationOriginal, Case == "Train",select = - Case)
testing <- subset(segmentationOriginal, Case == "Test",select = - Case)
cntrl <- rpart.control(maxdepth = 5, minsplit = 0, cp = -1)
library(rpart)
library(rpart.plot)
cntrl <- rpart.control(maxdepth = 5, minsplit = 0, cp = -1)
set.seed(125)
model <- train(Class ~., method= "rpart", data = training,
control =cntrl)
model
?predict.train
names(testing)[1:5]
newData <- testing[1:4,]
newData[1:4,] <- NA
newData$TotalIntenCh2 <- c(23000,50000,57000,NA)
newData$FiberWidthCh1 <- c(10,10,8,8)
newData$PerimStatusCh1 <- c(2,NA,NA,2)
newData$VarIntenCh4 <- c(NA,100,100,100)
result <- predict(model, newdata = newData, na.action = na.pass)
result
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
library(caret)
inTrain <- sample(seq(along = y), length(y)/2 , replace = TRUE)
inTrain = sample(1:nrow(vowel.train), nrow(vowel.train)/2, replace = TRUE)
training<- vowel.train[inTrain,]
testing<- vowel.train[-inTrain,]
set.seed(33833)
Forest<-train(training[,-y] ,training[,y],method="rf",ntree=1000,mtry=10,replace=TRUE,nodesize=10,importance=TRUE,proximity=TRUE)
names(vowel.train)
Forest<-train(training[,-1] ,training[,1],method="rf",ntree=1000,mtry=10,replace=TRUE,nodesize=10,importance=TRUE,proximity=TRUE)
modFit<-train( y~.,data=training,method="rf",ntree=1000,mtry=10,replace=TRUE,nodesize=10,importance=TRUE,proximity=TRUE)
modFit<-train( y~.,data=training,method="rf",ntree=1000,mtry=10,nodesize=10,importance=TRUE,proximity=TRUE)
modFit<-train( y~.,data=training,method="rf",ntree=1000,mtry=10,importance=TRUE,proximity=TRUE)
inTrain<-createDataPartition(vowel.train$y,p=0.7,list=FALSE)
training<- vowel.train[inTrain,]
testing<- vowel.train[-inTrain,]
set.seed(33833)
modFit<-train( y~.,data=training,method="rf",ntree=1000,mtry=10,importance=TRUE,prox=TRUE)
modFit<-train( y~.,data=training,method="rf",ntree=1000,mtry=10,prox=TRUE)
modFit<-train( y~.,data=training,method="rf",prox=TRUE)
it.rf<- randomForest(training[,-1], training[,1], ntree= 100,prox=TRUE,importance=TRUE,trControl =trainControl(method = "cv", number = 4, allowParallel = TRUE)
)
table(predict(fit.rf), training$y)
table(predict(it.rf), training$y)
varImpPlot(it.rf)
imp = importance(it.rf)
impvar = rownames(imp)[order(imp[, 1], decreasing=TRUE)]
impvar
(impor<-varImp(modFit,scale=FALSE))
(impor<-varImp(it.rf,scale=FALSE))
(imp = importance(modFit))
?importance
(imp = importance(modFit, scale= F))
library(randomForest)
(imp = importance(modFit, scale= F))
imp <- importance(modFit)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
missClass = function(values,prediction)
{sum(((prediction > 0.5)*1) != values)/length(values)}
glm.fit <- glm(chd ~ age +alcohol +obesity + tobacco +typea +ldl,family=binomial(”logit”), data= trainSA)
glm.fit <- glm(chd ~ age +alcohol +obesity + tobacco +typea +ldl,family=binomial("logit"), data= trainSA)
glm.pred=predict(glm.fit, testSA,type="response")
train.err <- trainSA$chd – round(predict(glm.fit,trainSA,type="response"))
train.err <- trainSA$chd - round(predict(glm.fit,trainSA,type="response"))
test.err <- testSA$chd - round(predict(glm.fit,testSA,type="response"))
missClass(testSA$chd,glm.pred)
missClass(trainSA$chd,glm.pred)
missClass(train.err,glm.pred)
missClass(test.err,glm.pred)
sum(((prediction > 0.5)*1) != trainSA$chd)/length(trainSA$chd)
sum(((glm.pred > 0.5)*1) != trainSA$chd)/length(trainSA$chd)
sum(((glm.pred > 0.5)*1) != mean(trainSA$chd))/length(trainSA$chd)
install.packages("RGLM")
?trainControl
library(varSelRF)
install.packages("varSelRF")
matrix(runif(10*4, min=0, max=0.2),
nrow=10, ncol=4)
set.seed(435)
idx <- sample(1:nrow(iris), 10)
# remove class labels
new.data <- iris[idx,-5]
# add random noise
new.data <- new.data + matrix(runif(10*4, min=0, max=0.2),
nrow=10, ncol=4)
# label new data
pred <- predict(ds, iris2, new.data)
library(fpc)
iris2 <- iris[-5] # remove class tags
ds <- dbscan(iris2, eps = 0.42, MinPts = 5)
help("fpc-package")
pred <- predict(ds, iris2, new.data)
pred
ds
?dbscan
plotcluster(iris2, ds$cluster)
set.seed(2835)
# draw a sample of 40 records from the iris data, so that the
# clustering plot will not be over crowded
idx <- sample(1:dim(iris)[1], 40)
irisSample <- iris[idx, ]
# remove class label
irisSample$Species <- NULL
# hierarchical clustering
hc <- hclust(dist(irisSample), method = "ave")
groups <- cutree(hc, k = 3)
plot(hc, hang = -1, labels = iris$Species[idx])
rect.hclust(hc, k = 3)
groups <- cutree(hc, k = 3)
library('caret')
library('mlbench')
library('pROC')
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTrain,]
testing <- Sonar[-inTrain,]
my_control <- trainControl(
method='boot',
number=25,
savePredictions=TRUE,
classProbs=TRUE,
index=createResample(training$Class, 25),
summaryFunction=twoClassSummary)
library('rpart')
library('caretEnsemble')
model_list <- caretList(
Class~., data=training,
trControl=my_control,
methodList=c('glm', 'rpart'))
p <- as.data.frame(predict(model_list, newdata=head(testing)))
p
library('mlbench')
library('randomForest')
library('nnet')
model_list_big <- caretList(
Class~., data=training,
trControl=my_control,
metric='ROC',
methodList=c('glm', 'rpart'),
tuneList=list(
rf1=caretModelSpec(method='rf', tuneGrid=data.frame(.mtry=2)),
rf2=caretModelSpec(method='rf', tuneGrid=data.frame(.mtry=10), preProcess='pca'),
nn=caretModelSpec(method='nnet', tuneLength=2, trace=FALSE)
)
)
model_list_big
model_list
?caretModelSpec
caretModelSpec('model_list', tuneLength=5, preProcess='ica')
?train
?tuneList
?tuneList
caretModelSpec('rf', tuneLength=5, preProcess='ica')
library(caretEnsemble)
help("caretEnsemble")
models <- caretList(iris[1:50,1:2], iris[1:50,3], methodList=c('glm', 'rpart'))
ens <- caretEnsemble(models)
summary(ens)
models <- caretList(iris[1:50,1:3], methodList=c('glm', 'rpart'))
models <- caretList(iris[1:50,1:3], iris[1:50,4], methodList=c('glm', 'rpart'))
?
nominalTrainWorkflow
library(mlr)
?nominalTrainWorkflow
help(mlr)
help(package="mlr")
task = makeClassifTask(data = iris, target = "Species")
rdesc = makeResampleDesc("CV", iters = 2)
r = resample(makeLearner("classif.qda"), task, rdesc)
print(r$aggr)
print(r$measures.test)
print(r$pred)
task = makeClassifTask(data = iris, target = "Species")
rdesc = makeResampleDesc("CV", iters = 2)
r = resample(makeLearner("classif.rf"), task, rdesc)
print(r$aggr)
print(r$measures.test)
print(r$pred)
names(r)
r$measures.train
r$extract
?caretModelSpec
my_control <- trainControl(
method='boot',
number=25,
savePredictions=TRUE,
classProbs=TRUE,
index=createResample(training$Class, 25),
summaryFunction=twoClassSummary,caretModelSpec('rf', tuneLength=5, preProcess='ica'))
model_list <- caretList(
Class~., data=training,
trControl=my_control,
methodList=c('glm', 'rpart'))
print(model_list)
p <- as.data.frame(predict(model_list, newdata=head(testing)))
p
modelCor(resamples(model_list))
greedy_ensemble <- caretEnsemble(model_list)
summary(greedy_ensemble)
library('caTools')
model_preds <- lapply(model_list, predict, newdata=testing, type='prob')
model_preds <- lapply(model_preds, function(x) x[,'M'])
model_preds <- data.frame(model_preds)
ens_preds <- predict(greedy_ensemble, newdata=testing)
model_preds$ensemble <- ens_preds
colAUC(model_preds, testing$Class)
varImp(greedy_ensemble)
order[varImp(greedy_ensemble)]
?order
myvar <-varImp(greedy_ensemble)
order(myvar, decreasing = T)
sort.list(myvar, decreasing = TRUE)
glm_ensemble <- caretStack(
model_list,
method='glm',
metric='acc',
trControl=trainControl(
method='boot',
number=10,
savePredictions=TRUE,
classProbs=TRUE,
summaryFunction=twoClassSummary
)
)
model_preds2 <- model_preds
model_preds2$ensemble <- predict(glm_ensemble, newdata=testing, type='prob')$M
CF <- coef(glm_ensemble$ens_model$finalModel)[-1]
?colAUC
?colACC
?acc
measureACC(model_preds2, testing$Class)
colAUC(model_preds2, testing$Class)
CF/sum(CF)
?plot.enet
?mod
?mode
setwd("~/R_work/ML")
library(parallel);library(doSNOW)
machineCores <- detectCores()
registerDoSNOW(machineCores)
train.df<-read.csv("pml-training.csv",header=TRUE)
del.col <- which(colSums(is.na(train.df))>10000)
train.df <- train.df[,-del.col]
train.df <- train.df[,(train.df[1,]!="")]
train.df<- train.df[!names(train.df) %in% c("X","user_name")]
comboInfo <- findLinearCombos(train.df[,c(1:2,5:57)])
library(caret)
comboInfo <- findLinearCombos(train.df[,c(1:2,5:57)])
nzv<-nearZeroVar(train.df)
train.df$new_window<-NULL
dCor <- cor(train.df[,c(1,2,4:56)])
findCorrelation(dCor, cutoff = .99)
names(train.df)[13]
train.df$accel_belt_y<-NULL
dim(train.df)
inTrain <-createDataPartition(y=train.df$classe,p=.75,list=FALSE)
training <-train.df[inTrain,]
testing <- train.df[-inTrain,]
library(wsrf)
model.wsrf <- wsrf(classe ~. , data= training, mtry=6)
wsrf.preds <- predict(model.wsrf, newdata= training, type="class")
correlation(model.wsrf)
oob.error.rate(model.wsrf)
impvar <- sort(var.imp, decreasing=TRUE)
impvar; length(impvar) [1] 55
imp.df <- names(impvar)[1:35]
trim <- training[,imp.df]
classe <- training$classe
training <- data.frame (classe, trim)
dim(training)
var.imp <- varCounts.wsrf(model.wsrf)
impvar <- sort(var.imp, decreasing=TRUE)
impvar; length(impvar) [1] 55
imp.df <- names(impvar)[1:35]
trim <- training[,imp.df]
classe <- training$classe
training <- data.frame (classe, trim)
dim(training)
names(training)[1]
set.seed(4582)
cvCtrl <- trainControl(method = "repeatedcv",repeats = 3)
model.lda <-
train(classe~.,data=training,method="lda",trControl= cvCtrl)
pred.lda<- predict(model.lda, testing);
confusionMatrix(pred.lda,testing$classe);
library(C50);library(rpart)
model.C5Rules <- C5.0(classe ~ ., data = training, rules=TRUE)
pred.C5 <- predict( model.C5Rules,testing[,-1],type = "class")
table(pred.C5, testing[,2])
table(pred.C5)
table(pred.C5,data.test$classe)
C5imp(model.C5Rules, metric = "splits")
tuned.rpart <- train(classe ~ ., data = training,method = "rpart",
tuneLength = 30,trControl = cvCtrl)
p.tuned.rpart = predict(tuned.rpart,testing)
confusionMatrix(p.tuned.rpart,testing$classe)
grid <- expand.grid(.model = "tree", .trials = c(1:100),.winnow = FALSE)
tuned.C5 <- C5.0(classe ~ ., data = training,
metric = "ROC",tuneGrid = grid,trControl = cvCtrl)
p.tuned.C5 = predict(tuned.C5,testing)
model.ada <- boosting(classe ~., data =training, boos=TRUE, mfinal=10)
library(adabag)
model.ada <- boosting(classe ~., data =training, boos=TRUE, mfinal=10)
ada.pred <- predict(object = model.ada, newdata = data.test, type = "class")
ada.pred$confusion;importanceplot(model.ada)
ada.pred <- predict(object = model.ada, newdata = testing, type = "class")
ada.pred$confusion;importanceplot(model.ada)
p.tuned.rpart = predict(tuned.rpart,testing)
p.tuned.C5 = predict(tuned.C5,testing)
qplot(p.tuned.rpart, p.tuned.C5, color=classe, data=testing)
equal.Preds = (p.tuned.rpart== p.tuned.C5)
sum(equal.Preds)
confusionMatrix(p.tuned.rpart,p.tuned.C5)
qplot(num_window,cvtd_timestamp ,colour=equal.Preds,data=testing)
pred.df <-data.frame(p.tuned.rpart, p.tuned.C5, classe= testing$classe)
comb.model <- train(classe ~., method= "gam",data= pred.df)
combPred <- predict(comb.model, pred.df)
pred.rpart <- predict(tuned.rpart, test.df)
pred.C5 <- predict(tuned.C5, test.df)
test.df<-read.csv("pml-testing.csv",header=TRUE)
pred.rpart <- predict(tuned.rpart, test.df)
pred.C5 <- predict(tuned.C5, test.df)
(comb.model.acc <-sum(predict( comb.model,testing)==
testing$classe)/length(testing$classe))
(model.lda.acc <-sum(predict(model.lda,testing)==
testing$classe)/length(testing$classe))
(tuned.rpart.acc <-sum(predict(tuned.rpart,testing)==
testing$classe)/length(testing$classe))
(tuned.C5.acc <-sum(predict(tuned.C5,testing)==
testing$classe)/length(testing$classe))
(model.C5Rules.acc <-sum(predict( model.C5Rules,testing)==
testing$classe)/length(testing$classe))
(submit<-predict(model.lda,test.df))
(submit<-predict(tuned.rpart,test.df))
(submit<-predict(tuned.C5,test.df))
(submit<-predict(model.C5Rules,test.df))
featurePlot(x= train.df[,c("roll_belt","cvtd_timestamp ","num_window")],y= train.df$classe,plot="pairs")
names(train.df)[1:10]
featurePlot(x= train.df[,3:5],y= train.df$classe,plot="pairs")
??featurePlot
featurePlot(x= train.df[,3:5],y= train.df$classe,plot="ellipse")
featurePlot(x= train.df[,3:5],y= train.df$classe,"strip", jitter=TRUE)
plot(tuned.C5)
plot(tuned.rpart, scales = list(x = list(log = 10)))
